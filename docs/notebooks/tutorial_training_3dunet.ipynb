{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training of 3D U-Net for high-speed movies\n",
    "\n",
    "This tutorial explains the creation of training data and the training of a 3D U-Net neural network model for the prediction of sarcomere Z-bands from high-speed microscopy movies of contracting cardiomyocytes. SarcAsM uses our package `bio-image-unet`, see [https://github.com/danihae/bio-image-unet](https://github.com/danihae/bio-image-unet). We strongly recommend using GPU-equipped workstation or server for training and prediction. Make sure that [CUDA toolkit](https://developer.nvidia.com/cuda-toolkit-archive) along the respective version of [PyTorch](https://pytorch.org/get-started/locally/) are installed and verify the installation by \n",
    "```python \n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation of training data set\n",
    "\n",
    "We recommend a training data set of 20-100 movie segments of each 100-200 frames. Since manual tracing of Z-bands in ~1000s of image is not feasible, labels are generated in two-step procedure: \n",
    "\n",
    "1. Randomly select 20-50 single images from set of movies, manually annotate these, and then train 2D U-Net model. Alternatively, use our generalist or other pretrained model.  \n",
    "2. Predict movies with 2D U-Net and then process resulting labels by removing flickering artifacts and "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# create folders for training data\n",
    "dir_training_data = '../../training_data/unet3d/'  # adapt path\n",
    "dir_training_data_movies = dir_training_data + 'movies/'\n",
    "dir_training_data_labels = dir_training_data + 'labels/'\n",
    "dir_training_data_prelim_labels = dir_training_data + 'prelim_labels/'\n",
    "os.makedirs(dir_training_data_movies, exist_ok=True)\n",
    "os.makedirs(dir_training_data_labels, exist_ok=True)\n",
    "os.makedirs(dir_training_data_prelim_labels, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create set of movie sequences and predict with 2D U-Net\n",
    "\n",
    "Here we assume that 2D U-Net model already exists. For training of 2D U-Net, follow instruction [here](../notebooks/tutorial_training_unet.html#). "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import tifffile\n",
    "\n",
    "# randomly select 50 movie segments from larger data set (alternatively manually select movies)\n",
    "n_movies = 50\n",
    "len_sequence = 128\n",
    "dir_movies = 'path/all_movies/'  # adapt\n",
    "movies = glob.glob(dir_movies + '*/*.tif')  # adapt when necessary\n",
    "movies_sample = random.sample(movies, n_movies)\n",
    "\n",
    "for movie in movies_sample:\n",
    "    name = os.path.basename(os.path.dirname(movie)) + '_' + os.path.basename(movie)[:-4]\n",
    "    imgs = tifffile.imread(movie)\n",
    "    start_frame_random = random.randint(0, imgs.shape[0]-len_sequence-1)\n",
    "    random_frames = imgs[start_frame_random: start_frame_random+len_sequence]\n",
    "    tifffile.imwrite(dir_training_data_movies + name + f'_{start_frame_random}-{start_frame_random+len_sequence}.tif', random_frames)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import bio_image_unet.unet as unet\n",
    "\n",
    "# predict sequences with 2D U-Net\n",
    "training_sequences = glob.glob(dir_training_data_movies + '*.tif')\n",
    "model_params = 'path/to/2d_unet/model.pth'  # adapt path of model\n",
    " \n",
    "for sequence in training_sequences:\n",
    "    name = os.path.basename(sequence)\n",
    "    unet.Predict(sequence, dir_training_data_prelim_labels + name, model_params, resize_dim=(256, 1024), show_progress=False)  # change parameters when needed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Process preliminary labels\n",
    "The preliminary training data labels are processed by analyzing the sarcomere vectors for each frame, [see details here](../autoapi/sarcasm/structure/index.html#sarcasm.structure.Structure.analyze_sarcomere_vectors), and creating binary masks of sarcomeres, i.e., regions of sarcomeres in each frame. The mean mask of these sarcomere masks is then thresholded and dilated to form a refined mask. This dilated mask is applied to the label images to exclude unwanted regions. The labels are then thresholded and connected components are labeled. The labeled objects are filtered by volume to remove small objects. Finally, the processed masks are saved as TIFF files for use in training the 3D U-Net model."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import label, binary_dilation\n",
    "from sarcasm import SarcAsM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_by_volume(labels, min_volume=None):\n",
    "    \"\"\"\n",
    "    Filter labeled objects by their volume.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: 3D numpy array of labeled objects.\n",
    "    - min_volume: Minimum volume threshold for filtering.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_labels: 3D numpy array of filtered labeled objects.\n",
    "    \"\"\"\n",
    "    # Get unique objects and their volumes\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    volumes = dict(zip(unique[1:], counts[1:]))  # Exclude background (label 0)\n",
    "\n",
    "    # Filter by volume if min_volume is specified\n",
    "    filtered_labels = labels.copy()\n",
    "    for obj_label, volume in volumes.items():\n",
    "        if min_volume is not None and volume < min_volume:\n",
    "            filtered_labels[filtered_labels == obj_label] = 0\n",
    "\n",
    "    return filtered_labels\n",
    "\n",
    "# Path to preliminary training data labels\n",
    "dir_training_data_prelim_labels = '../training_data/unet3d/prelim_labels/'\n",
    "training_sequences_labels_prelim = glob.glob(dir_training_data_prelim_labels + '*.tif')\n",
    "\n",
    "# Ensure the directory for final training data labels exists\n",
    "dir_training_data_labels = '../training_data/unet3d/labels/'\n",
    "os.makedirs(dir_training_data_labels, exist_ok=True)\n",
    "\n",
    "# Process each sequence of preliminary labels\n",
    "for sequence_labels in training_sequences_labels_prelim:\n",
    "    print(f'Processing {sequence_labels}')\n",
    "    name = os.path.basename(sequence_labels)\n",
    "    imgs_labels = tifffile.imread(sequence_labels)\n",
    "\n",
    "    pixelsize = 0.065\n",
    "    sarc_obj = SarcAsM(sequence_labels, pixelsize=pixelsize, restart=False)\n",
    "    \n",
    "    sarc_obj.analyze_sarcomere_length_orient(save_all=False, score_threshold=0.2)\n",
    "    \n",
    "    # Read the sarcomere masks\n",
    "    masks = tifffile.imread(sarc_obj.file_sarcomere_mask)\n",
    "    masks_mean = masks.mean(axis=0)\n",
    "    mask_thres = masks_mean > 0.5\n",
    "    \n",
    "    # Dilate the thresholded masks\n",
    "    masks_thres_dilated = binary_dilation(mask_thres, structure=np.ones((11, 11)))\n",
    "    \n",
    "    # Plot the mean masks and overlaid dilated masks\n",
    "    plt.figure()\n",
    "    plt.imshow(masks_mean)\n",
    "    plt.title(\"Mean Masks\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(tifffile.imread(sarc_obj.file_sarcomeres)[0])\n",
    "    plt.imshow(masks_thres_dilated, alpha=0.5)\n",
    "    plt.title(\"Z-bands with Overlaid Masks\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Threshold the labels\n",
    "    imgs_labels_out = imgs_labels > 20\n",
    "    \n",
    "    # Apply the dilated mask to the labels\n",
    "    imgs_labels_out[:, ~masks_thres_dilated] = 0\n",
    "    \n",
    "    # Label the connected components\n",
    "    labels = label(imgs_labels_out)[0]\n",
    "    filtered_labels = filter_by_volume(labels, min_volume=200)\n",
    "    \n",
    "    # Generate the final mask\n",
    "    masks_out = filtered_labels > 0\n",
    "    \n",
    "    # Save the final mask as a TIFF file\n",
    "    tifffile.imwrite(os.path.join(dir_training_data_labels, name), masks_out.astype('uint8') * 255)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Augmenting movies to include rapid high-frequency motion \n",
    "\n",
    "We augmented movie sequences by simulating rapidly moving Z-bands, which are under-represented in the dataset. The augmentation is performed by applying random sinusoidal shifts to both the image and corresponding label sequences."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy import ndimage\n",
    "\n",
    "# Directories for images and masks (adapt!)\n",
    "dir_images = 'D:/git/SarcAsM/training_data/unet3d/movies/'\n",
    "dir_masks = 'D:/git/SarcAsM/training_data/unet3d/labels/'\n",
    "\n",
    "# Directories for shifted (augmented) images and masks\n",
    "dir_images_shifted = os.path.join(dir_images, 'shifted/')\n",
    "dir_masks_shifted = os.path.join(dir_masks, 'shifted/')\n",
    "\n",
    "os.makedirs(dir_images_shifted, exist_ok=True)\n",
    "os.makedirs(dir_masks_shifted, exist_ok=True)\n",
    "\n",
    "# Get the list of training sequences\n",
    "training_sequences = glob.glob(dir_images + '*.tif')\n",
    "\n",
    "# Process each image sequence \n",
    "for img_seq in training_sequences:\n",
    "    name = os.path.basename(img_seq)\n",
    "    label_seq = os.path.join(dir_masks, name)\n",
    "    \n",
    "    # Load images and labels\n",
    "    imgs = tifffile.imread(img_seq)\n",
    "    labels = tifffile.imread(label_seq)\n",
    "    \n",
    "    # Random frequencies and amplitudes for sinusoidal shifts (adapt when necessary)\n",
    "    freq_x, amp_x = random.uniform(0, 0.5), random.uniform(5, 25)\n",
    "    freq_y, amp_y = random.uniform(0, 0.5), random.uniform(0, 5)\n",
    "    \n",
    "    z_range = np.arange(imgs.shape[0])\n",
    "    x_shift = amp_x * np.sin(freq_x * z_range)\n",
    "    y_shift = amp_y * np.sin(freq_y * z_range)\n",
    "\n",
    "    shifted_imgs = np.zeros_like(imgs)\n",
    "    shifted_labels = np.zeros_like(labels)\n",
    "    \n",
    "    # Apply the shifts to each frame in the sequence\n",
    "    for t in range(imgs.shape[0]):\n",
    "        shifted_imgs[t] = ndimage.shift(imgs[t], (y_shift[t], x_shift[t]), mode='constant', cval=0.0)\n",
    "        shifted_labels[t] = ndimage.shift(labels[t], (y_shift[t], x_shift[t]), mode='constant', cval=0.0)\n",
    "    \n",
    "    name_shifted = name.replace('.tif', '_random_shift.tif')\n",
    "    \n",
    "    # Save the shifted images and labels\n",
    "    tifffile.imwrite(os.path.join(dir_images_shifted, name_shifted), shifted_imgs)\n",
    "    tifffile.imwrite(os.path.join(dir_masks_shifted, name_shifted), shifted_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "### Prepare and process training data\n",
    "\n",
    "Prior to training, the training images and labels are processed and augmented. For the different options for processing and augmentation (add noise, blur, adjust contrast, ...) see docstring or [API reference](../autoapi/bio_image_unet/unet3d/data/index.html)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import bio_image_unet.unet3d as unet3d\n",
    "\n",
    "# path to training data (images and labels with identical names in separate folders)\n",
    "dir_images = f'D:/git/SarcAsM/training_data/unet3d/images/'\n",
    "dir_masks = f'D:/git/SarcAsM/training_data/unet3d/labels/'\n",
    "\n",
    "# path to directory for training data generation (is created automatically, drive should have enough storage)\n",
    "data_path = 'D:/git/SarcAsM/training_temp/20240430_unet3d_data/'\n",
    "\n",
    "# generation of training data set and augmentation\n",
    "dataset = unet3d.DataProcess([dir_images, dir_masks], data_path=data_path, create=False,\n",
    "                           noise_amp=0, brightness_contrast=(0.15, 0.15), aug_factor=2, clip_threshold=(0., 99.95), \n",
    "                           dim_out=(128, 128, 128), shiftscalerotate=(0, 0, 0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Set training parameters and train       \n",
    "\n",
    "For different training parameters, check the docstring `print(unet3d.Trainer.__doc__)` or [API reference](../autoapi/bio_image_unet/unet3d/train/index.html)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# temp folder\n",
    "save_dir = 'path/training_temp/training_unet3d/'\n",
    "\n",
    "# initialize Trainer object\n",
    "training = unet3d.Trainer(dataset, num_epochs=100 ,batch_size=4, loss_function='BCEDice', n_filter=16, loss_params=(1, 1), load_weights=None, lr=0.0005, save_iter=True, save_dir=save_dir, use_interpolation=True)\n",
    "\n",
    "# start training\n",
    "training.start()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After training is completed, the model parameters `model.pth` are stored in the `save_dir`. "
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
